{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ea4a97",
      "metadata": {
        "id": "81ea4a97"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D,  concatenate, Conv2DTranspose, Dropout\n",
        "\n",
        "def UNet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = inputs\n",
        "\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    #Expansive path\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f7b391",
      "metadata": {
        "id": "c6f7b391"
      },
      "outputs": [],
      "source": [
        "def repeat_elem(tensor, rep):\n",
        "\n",
        "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "# Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "# Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = layers.BatchNormalization()(result)\n",
        "    return result_bn\n",
        "\n",
        "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jpl13SFuBFY8",
      "metadata": {
        "id": "jpl13SFuBFY8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "def Attention_UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Attention UNet,\n",
        "    Attention_UNet\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
        "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
        "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
        "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
        "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"Attention_UNet\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1775db76",
      "metadata": {
        "id": "1775db76"
      },
      "outputs": [],
      "source": [
        "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation('relu')(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "\n",
        "    res_path = layers.add([shortcut, conv])\n",
        "    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
        "    return res_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c33917",
      "metadata": {
        "id": "d0c33917"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "def Res_UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "\n",
        "    # DownRes 2\n",
        "    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, conv_16], axis=3)\n",
        "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, conv_32], axis=3)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, conv_64], axis=3)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, conv_128], axis=3)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model\n",
        "    model = models.Model(inputs, conv_final, name=\"res_UNet\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702b253a",
      "metadata": {
        "id": "702b253a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "def Att_Res_UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Rsidual UNet, with attention\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "    # input data\n",
        "    # dimension of the image depth\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "    axis = 3\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, double residual convolution + pooling\n",
        "    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=axis)\n",
        "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=axis)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=axis)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=axis)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=axis)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"AttentionResUNet\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8107766e",
      "metadata": {
        "id": "8107766e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as ' C extension module was built for another version of psutil (5.6.2 instead of 5.9.8); you may try to ' could not be imported from '5.6.2 instead of 5.9.8'.\n",
            "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "def fractal_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "    conv_a1 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv_a1 = layers.BatchNormalization(axis=3)(conv_a1)\n",
        "    conv_a1 = layers.Activation('relu')(conv_a1)\n",
        "\n",
        "    conv_a1 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv_a1)\n",
        "    if batch_norm is True:\n",
        "        conv_a1 = layers.BatchNormalization(axis=3)(conv_a1)\n",
        "    conv_a1 = layers.Activation('relu')(conv_a1)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv_a1 = layers.Dropout(dropout)(conv_a1)\n",
        "\n",
        "\n",
        "    conv_a2 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv_a2 = layers.BatchNormalization(axis=3)(conv_a2)\n",
        "    conv_a2 = layers.Activation('relu')(conv_a2)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv_a2 = layers.Dropout(dropout)(conv_a2)\n",
        "\n",
        "\n",
        "    conv_a3 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv_a3 = layers.BatchNormalization(axis=3)(conv_a3)\n",
        "    conv_a3 = layers.Activation('relu')(conv_a3)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv_a3 = layers.Dropout(dropout)(conv_a3)\n",
        "\n",
        "    fractal_join1 = layers.add([conv_a1, conv_a2])\n",
        "    #fractal_join1 = layers.Activation('relu')(fractal_join1)    #Activation after addition with shortcut (Original residual block)\n",
        "    x2 = fractal_join1\n",
        "\n",
        "    conv_a4 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x2)\n",
        "    if batch_norm is True:\n",
        "        conv_a4 = layers.BatchNormalization(axis=3)(conv_a4)\n",
        "    conv_a4 = layers.Activation('relu')(conv_a4)\n",
        "\n",
        "    conv_a4 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv_a4)\n",
        "    if batch_norm is True:\n",
        "        conv_a4 = layers.BatchNormalization(axis=3)(conv_a4)\n",
        "    conv_a4 = layers.Activation('relu')(conv_a4)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv_a4 = layers.Dropout(dropout)(conv_a4)\n",
        "\n",
        "    conv_a5 = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x2)\n",
        "    if batch_norm is True:\n",
        "        conv_a5 = layers.BatchNormalization(axis=3)(conv_a5)\n",
        "    conv_a5 = layers.Activation('relu')(conv_a5)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv_a5 = layers.Dropout(dropout)(conv_a5)\n",
        "\n",
        "    #fractal_join2 = layers.add([conv_a4, conv_a5, conv_a3])\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "    return fractal_join2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa50986",
      "metadata": {
        "id": "2aa50986"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "def FractalSpiNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = fractal_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "\n",
        "    # DownRes 2\n",
        "    conv_64 = fractal_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = fractal_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = fractal_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = fractal_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, conv_16], axis=3)\n",
        "    up_conv_16 = fractal_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, conv_32], axis=3)\n",
        "    up_conv_32 = fractal_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, conv_64], axis=3)\n",
        "    up_conv_64 = fractal_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, conv_128], axis=3)\n",
        "    up_conv_128 = fractal_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model\n",
        "    model = models.Model(inputs, conv_final, name=\"FractalSpiNet\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e783ded",
      "metadata": {
        "id": "3e783ded"
      },
      "source": [
        "# DATA INPUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90bd4cfc",
      "metadata": {
        "id": "90bd4cfc"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_directory =\"/home/sysadmin/RKY/unet/newaug_aksiyal_son_silinmis/image/\"\n",
        "mask_directory = \"/home/sysadmin/RKY/unet/newaug_aksiyal_son_silinmis/mask/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3db84d3",
      "metadata": {
        "id": "d3db84d3"
      },
      "outputs": [],
      "source": [
        "\n",
        "SIZE = 128\n",
        "image_dataset = []\n",
        "mask_dataset = []\n",
        "images = sorted(os.listdir(image_directory))\n",
        "for i, image_name in enumerate(images):\n",
        "    if (image_name.split('.')[1] == 'png'):\n",
        "        image = cv2.imread(image_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        image_dataset.append(np.array(image))\n",
        "\n",
        "\n",
        "masks = sorted(os.listdir(mask_directory))\n",
        "for i, image_name in enumerate(masks):\n",
        "    if (image_name.split('.')[1] == 'png'):\n",
        "        image = cv2.imread(mask_directory+image_name, 0)\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.resize((SIZE, SIZE))\n",
        "        mask_dataset.append(np.array(image))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c61a289",
      "metadata": {
        "id": "3c61a289"
      },
      "source": [
        "# NORMALIZATION IMAGES AND MASKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23be76b",
      "metadata": {
        "id": "c23be76b",
        "outputId": "07d86ad2-2fe2-44f4-bffd-6d2721398da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 128, 1)\n",
            "(128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "image_dataset = np.expand_dims(normalize(np.array(image_dataset)),3)\n",
        "print(image_dataset[0].shape)\n",
        "mask_dataset = np.expand_dims((np.array(mask_dataset)),3)/255\n",
        "print(mask_dataset[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253c2d68",
      "metadata": {
        "id": "253c2d68"
      },
      "source": [
        "# MODEL SELCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "322fc156",
      "metadata": {
        "id": "322fc156",
        "outputId": "4242d210-937e-4e9b-d6c1-04e07c8887b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((862, 128, 128, 1),\n",
              " (216, 128, 128, 1),\n",
              " (862, 128, 128, 1),\n",
              " (216, 128, 128, 1))"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.20, random_state = 0)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9718ba5",
      "metadata": {
        "id": "d9718ba5"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1747414",
      "metadata": {
        "id": "a1747414",
        "outputId": "3d08e974-1b5f-4522-c29e-e0697ca0c40f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-77a452726b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(X_train))\n",
        "print(image_number)\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.subplot(1,4,1)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.reshape(X_train[image_number], (128, 128)), cmap='gray')\n",
        "plt.subplot(1,4,2)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.reshape(y_train[image_number], (128, 128)), cmap='gray')\n",
        "plt.subplot(1,4,3)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.reshape(X_train[image_number], (128, 128)),)\n",
        "plt.subplot(1,4,4)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.reshape(y_train[image_number], (128, 128)),)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a086435",
      "metadata": {
        "id": "3a086435"
      },
      "source": [
        "# TEMEL MODEL U-NET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1771c6",
      "metadata": {
        "id": "bc1771c6",
        "outputId": "87e4670b-10d4-4171-9989-5d699247e5f0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"UNet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 128, 128, 64) 640         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 128, 128, 64) 256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 128, 128, 64) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 128, 128, 64) 36928       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 128, 128, 64) 256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 128, 128, 64) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 64, 64, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 64, 64, 128)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 64, 64, 128)  147584      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 64, 64, 128)  512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 64, 64, 128)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 256)  1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 256)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 256)  590080      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 256)  1024        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 256)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 256)  0           activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 512)  1180160     max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 512)  2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 512)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 512)  2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 512)  2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 512)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 512)    0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 8, 8, 1024)   4719616     max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 1024)   4096        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 1024)   9438208     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 1024)   4096        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 16, 16, 1024) 0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 1536) 0           up_sampling2d_8[0][0]            \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 512)  7078400     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 512)  2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 512)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 512)  2359808     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 512)  2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 512)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 32, 32, 512)  0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 768)  0           up_sampling2d_9[0][0]            \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 256)  1024        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 256)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 32, 32, 256)  590080      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 256)  1024        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 256)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling2D) (None, 64, 64, 256)  0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 64, 64, 384)  0           up_sampling2d_10[0][0]           \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 64, 64, 128)  512         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 64, 64, 128)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 64, 64, 128)  147584      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 64, 64, 128)  512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 64, 64, 128)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_11 (UpSampling2D) (None, 128, 128, 128 0           activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 128, 128, 192 0           up_sampling2d_11[0][0]           \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 128, 128, 64) 256         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 128, 128, 64) 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 128, 128, 64) 36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 128, 128, 64) 256         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 128, 128, 64) 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 128, 128, 1)  65          activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 128, 128, 1)  4           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 128, 128, 1)  0           batch_normalization_56[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 31,401,349\n",
            "Trainable params: 31,389,571\n",
            "Non-trainable params: 11,778\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 16s 99ms/step - loss: 0.6356 - accuracy: 0.9606 - val_loss: 0.5176 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00001: saving model to /media/sysadmin/stock/weights_unet/13_unet-0001.hdf5\n",
            "Epoch 2/200\n",
            "108/108 [==============================] - 9s 79ms/step - loss: 0.5756 - accuracy: 0.9932 - val_loss: 0.5288 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00002: saving model to /media/sysadmin/stock/weights_unet/13_unet-0002.hdf5\n",
            "Epoch 3/200\n",
            "108/108 [==============================] - 9s 80ms/step - loss: 0.5282 - accuracy: 0.9958 - val_loss: 0.4973 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00003: saving model to /media/sysadmin/stock/weights_unet/13_unet-0003.hdf5\n",
            "Epoch 4/200\n",
            "108/108 [==============================] - 9s 82ms/step - loss: 0.4856 - accuracy: 0.9966 - val_loss: 0.4764 - val_accuracy: 0.9905\n",
            "\n",
            "Epoch 00004: saving model to /media/sysadmin/stock/weights_unet/13_unet-0004.hdf5\n",
            "Epoch 5/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.4477 - accuracy: 0.9968 - val_loss: 0.4278 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00005: saving model to /media/sysadmin/stock/weights_unet/13_unet-0005.hdf5\n",
            "Epoch 6/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.4122 - accuracy: 0.9973 - val_loss: 0.3986 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00006: saving model to /media/sysadmin/stock/weights_unet/13_unet-0006.hdf5\n",
            "Epoch 7/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.3803 - accuracy: 0.9974 - val_loss: 0.3610 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00007: saving model to /media/sysadmin/stock/weights_unet/13_unet-0007.hdf5\n",
            "Epoch 8/200\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.3515 - accuracy: 0.9975 - val_loss: 0.3393 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00008: saving model to /media/sysadmin/stock/weights_unet/13_unet-0008.hdf5\n",
            "Epoch 9/200\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.3273 - accuracy: 0.9972 - val_loss: 0.5290 - val_accuracy: 0.9087\n",
            "\n",
            "Epoch 00009: saving model to /media/sysadmin/stock/weights_unet/13_unet-0009.hdf5\n",
            "Epoch 10/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.3024 - accuracy: 0.9975 - val_loss: 0.2902 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00010: saving model to /media/sysadmin/stock/weights_unet/13_unet-0010.hdf5\n",
            "Epoch 11/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.2799 - accuracy: 0.9976 - val_loss: 0.2777 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00011: saving model to /media/sysadmin/stock/weights_unet/13_unet-0011.hdf5\n",
            "Epoch 12/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.2600 - accuracy: 0.9976 - val_loss: 0.2558 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00012: saving model to /media/sysadmin/stock/weights_unet/13_unet-0012.hdf5\n",
            "Epoch 13/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.2415 - accuracy: 0.9977 - val_loss: 0.2380 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00013: saving model to /media/sysadmin/stock/weights_unet/13_unet-0013.hdf5\n",
            "Epoch 14/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.2250 - accuracy: 0.9977 - val_loss: 0.2202 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00014: saving model to /media/sysadmin/stock/weights_unet/13_unet-0014.hdf5\n",
            "Epoch 15/200\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.2101 - accuracy: 0.9977 - val_loss: 0.2066 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00015: saving model to /media/sysadmin/stock/weights_unet/13_unet-0015.hdf5\n",
            "Epoch 16/200\n",
            "108/108 [==============================] - 9s 88ms/step - loss: 0.1959 - accuracy: 0.9978 - val_loss: 0.1906 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00016: saving model to /media/sysadmin/stock/weights_unet/13_unet-0016.hdf5\n",
            "Epoch 17/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.1829 - accuracy: 0.9978 - val_loss: 0.1791 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00017: saving model to /media/sysadmin/stock/weights_unet/13_unet-0017.hdf5\n",
            "Epoch 18/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.1710 - accuracy: 0.9978 - val_loss: 0.1678 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00018: saving model to /media/sysadmin/stock/weights_unet/13_unet-0018.hdf5\n",
            "Epoch 19/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.1604 - accuracy: 0.9978 - val_loss: 0.1617 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00019: saving model to /media/sysadmin/stock/weights_unet/13_unet-0019.hdf5\n",
            "Epoch 20/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.1506 - accuracy: 0.9978 - val_loss: 0.2223 - val_accuracy: 0.9871\n",
            "\n",
            "Epoch 00020: saving model to /media/sysadmin/stock/weights_unet/13_unet-0020.hdf5\n",
            "Epoch 21/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.1427 - accuracy: 0.9977 - val_loss: 0.1460 - val_accuracy: 0.9972\n",
            "\n",
            "Epoch 00021: saving model to /media/sysadmin/stock/weights_unet/13_unet-0021.hdf5\n",
            "Epoch 22/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.1331 - accuracy: 0.9978 - val_loss: 0.1376 - val_accuracy: 0.9973\n",
            "\n",
            "Epoch 00022: saving model to /media/sysadmin/stock/weights_unet/13_unet-0022.hdf5\n",
            "Epoch 23/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.1249 - accuracy: 0.9979 - val_loss: 0.1234 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00023: saving model to /media/sysadmin/stock/weights_unet/13_unet-0023.hdf5\n",
            "Epoch 24/200\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.1172 - accuracy: 0.9979 - val_loss: 0.1152 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00024: saving model to /media/sysadmin/stock/weights_unet/13_unet-0024.hdf5\n",
            "Epoch 25/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.1104 - accuracy: 0.9979 - val_loss: 0.1154 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00025: saving model to /media/sysadmin/stock/weights_unet/13_unet-0025.hdf5\n",
            "Epoch 26/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.1042 - accuracy: 0.9979 - val_loss: 0.1030 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00026: saving model to /media/sysadmin/stock/weights_unet/13_unet-0026.hdf5\n",
            "Epoch 27/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.0983 - accuracy: 0.9979 - val_loss: 0.0970 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00027: saving model to /media/sysadmin/stock/weights_unet/13_unet-0027.hdf5\n",
            "Epoch 28/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.0928 - accuracy: 0.9979 - val_loss: 0.0912 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00028: saving model to /media/sysadmin/stock/weights_unet/13_unet-0028.hdf5\n",
            "Epoch 29/200\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.0878 - accuracy: 0.9979 - val_loss: 0.0904 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00029: saving model to /media/sysadmin/stock/weights_unet/13_unet-0029.hdf5\n",
            "Epoch 30/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.0831 - accuracy: 0.9979 - val_loss: 0.0816 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00030: saving model to /media/sysadmin/stock/weights_unet/13_unet-0030.hdf5\n",
            "Epoch 31/200\n",
            "108/108 [==============================] - 9s 86ms/step - loss: 0.0783 - accuracy: 0.9980 - val_loss: 0.0772 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00031: saving model to /media/sysadmin/stock/weights_unet/13_unet-0031.hdf5\n",
            "Epoch 32/200\n",
            "108/108 [==============================] - 9s 85ms/step - loss: 0.0740 - accuracy: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00032: saving model to /media/sysadmin/stock/weights_unet/13_unet-0032.hdf5\n",
            "Epoch 33/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.0700 - accuracy: 0.9980 - val_loss: 0.0691 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00033: saving model to /media/sysadmin/stock/weights_unet/13_unet-0033.hdf5\n",
            "Epoch 34/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.0664 - accuracy: 0.9980 - val_loss: 0.0688 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00034: saving model to /media/sysadmin/stock/weights_unet/13_unet-0034.hdf5\n",
            "Epoch 35/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.0631 - accuracy: 0.9980 - val_loss: 0.0716 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00035: saving model to /media/sysadmin/stock/weights_unet/13_unet-0035.hdf5\n",
            "Epoch 36/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.0598 - accuracy: 0.9980 - val_loss: 0.0608 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00036: saving model to /media/sysadmin/stock/weights_unet/13_unet-0036.hdf5\n",
            "Epoch 37/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 9s 79ms/step - loss: 0.0567 - accuracy: 0.9980 - val_loss: 0.0568 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00037: saving model to /media/sysadmin/stock/weights_unet/13_unet-0037.hdf5\n",
            "Epoch 38/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0537 - accuracy: 0.9980 - val_loss: 0.0539 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00038: saving model to /media/sysadmin/stock/weights_unet/13_unet-0038.hdf5\n",
            "Epoch 39/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0510 - accuracy: 0.9980 - val_loss: 0.0511 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00039: saving model to /media/sysadmin/stock/weights_unet/13_unet-0039.hdf5\n",
            "Epoch 40/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0527 - accuracy: 0.9975 - val_loss: 0.0852 - val_accuracy: 0.9902\n",
            "\n",
            "Epoch 00040: saving model to /media/sysadmin/stock/weights_unet/13_unet-0040.hdf5\n",
            "Epoch 41/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0483 - accuracy: 0.9978 - val_loss: 0.0478 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00041: saving model to /media/sysadmin/stock/weights_unet/13_unet-0041.hdf5\n",
            "Epoch 42/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0446 - accuracy: 0.9980 - val_loss: 0.0453 - val_accuracy: 0.9972\n",
            "\n",
            "Epoch 00042: saving model to /media/sysadmin/stock/weights_unet/13_unet-0042.hdf5\n",
            "Epoch 43/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0420 - accuracy: 0.9980 - val_loss: 0.0433 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00043: saving model to /media/sysadmin/stock/weights_unet/13_unet-0043.hdf5\n",
            "Epoch 44/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0399 - accuracy: 0.9980 - val_loss: 0.0405 - val_accuracy: 0.9975\n",
            "\n",
            "Epoch 00044: saving model to /media/sysadmin/stock/weights_unet/13_unet-0044.hdf5\n",
            "Epoch 45/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0379 - accuracy: 0.9980 - val_loss: 0.0391 - val_accuracy: 0.9972\n",
            "\n",
            "Epoch 00045: saving model to /media/sysadmin/stock/weights_unet/13_unet-0045.hdf5\n",
            "Epoch 46/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0360 - accuracy: 0.9981 - val_loss: 0.0366 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00046: saving model to /media/sysadmin/stock/weights_unet/13_unet-0046.hdf5\n",
            "Epoch 47/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0343 - accuracy: 0.9981 - val_loss: 0.0350 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00047: saving model to /media/sysadmin/stock/weights_unet/13_unet-0047.hdf5\n",
            "Epoch 48/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0326 - accuracy: 0.9981 - val_loss: 0.0344 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00048: saving model to /media/sysadmin/stock/weights_unet/13_unet-0048.hdf5\n",
            "Epoch 49/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0311 - accuracy: 0.9981 - val_loss: 0.0321 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00049: saving model to /media/sysadmin/stock/weights_unet/13_unet-0049.hdf5\n",
            "Epoch 50/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0297 - accuracy: 0.9981 - val_loss: 0.0302 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00050: saving model to /media/sysadmin/stock/weights_unet/13_unet-0050.hdf5\n",
            "Epoch 51/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0284 - accuracy: 0.9981 - val_loss: 0.0302 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00051: saving model to /media/sysadmin/stock/weights_unet/13_unet-0051.hdf5\n",
            "Epoch 52/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0271 - accuracy: 0.9981 - val_loss: 0.0293 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00052: saving model to /media/sysadmin/stock/weights_unet/13_unet-0052.hdf5\n",
            "Epoch 53/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0258 - accuracy: 0.9981 - val_loss: 0.0276 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00053: saving model to /media/sysadmin/stock/weights_unet/13_unet-0053.hdf5\n",
            "Epoch 54/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0247 - accuracy: 0.9981 - val_loss: 0.0267 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00054: saving model to /media/sysadmin/stock/weights_unet/13_unet-0054.hdf5\n",
            "Epoch 55/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0236 - accuracy: 0.9981 - val_loss: 0.0252 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00055: saving model to /media/sysadmin/stock/weights_unet/13_unet-0055.hdf5\n",
            "Epoch 56/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0229 - accuracy: 0.9980 - val_loss: 0.0241 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00056: saving model to /media/sysadmin/stock/weights_unet/13_unet-0056.hdf5\n",
            "Epoch 57/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0216 - accuracy: 0.9981 - val_loss: 0.0242 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00057: saving model to /media/sysadmin/stock/weights_unet/13_unet-0057.hdf5\n",
            "Epoch 58/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0206 - accuracy: 0.9981 - val_loss: 0.0240 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00058: saving model to /media/sysadmin/stock/weights_unet/13_unet-0058.hdf5\n",
            "Epoch 59/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0197 - accuracy: 0.9981 - val_loss: 0.0220 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00059: saving model to /media/sysadmin/stock/weights_unet/13_unet-0059.hdf5\n",
            "Epoch 60/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0188 - accuracy: 0.9981 - val_loss: 0.0217 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00060: saving model to /media/sysadmin/stock/weights_unet/13_unet-0060.hdf5\n",
            "Epoch 61/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 0.0225 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00061: saving model to /media/sysadmin/stock/weights_unet/13_unet-0061.hdf5\n",
            "Epoch 62/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0171 - accuracy: 0.9981 - val_loss: 0.0192 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00062: saving model to /media/sysadmin/stock/weights_unet/13_unet-0062.hdf5\n",
            "Epoch 63/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0164 - accuracy: 0.9981 - val_loss: 0.0192 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00063: saving model to /media/sysadmin/stock/weights_unet/13_unet-0063.hdf5\n",
            "Epoch 64/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0157 - accuracy: 0.9981 - val_loss: 0.0185 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00064: saving model to /media/sysadmin/stock/weights_unet/13_unet-0064.hdf5\n",
            "Epoch 65/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 0.0204 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00065: saving model to /media/sysadmin/stock/weights_unet/13_unet-0065.hdf5\n",
            "Epoch 66/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0145 - accuracy: 0.9981 - val_loss: 0.0169 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00066: saving model to /media/sysadmin/stock/weights_unet/13_unet-0066.hdf5\n",
            "Epoch 67/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 0.0185 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00067: saving model to /media/sysadmin/stock/weights_unet/13_unet-0067.hdf5\n",
            "Epoch 68/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 0.0176 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00068: saving model to /media/sysadmin/stock/weights_unet/13_unet-0068.hdf5\n",
            "Epoch 69/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0172 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00069: saving model to /media/sysadmin/stock/weights_unet/13_unet-0069.hdf5\n",
            "Epoch 70/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.0154 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00070: saving model to /media/sysadmin/stock/weights_unet/13_unet-0070.hdf5\n",
            "Epoch 71/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.0170 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00071: saving model to /media/sysadmin/stock/weights_unet/13_unet-0071.hdf5\n",
            "Epoch 72/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.0152 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00072: saving model to /media/sysadmin/stock/weights_unet/13_unet-0072.hdf5\n",
            "Epoch 73/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0108 - accuracy: 0.9981 - val_loss: 0.0132 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00073: saving model to /media/sysadmin/stock/weights_unet/13_unet-0073.hdf5\n",
            "Epoch 74/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.0146 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00074: saving model to /media/sysadmin/stock/weights_unet/13_unet-0074.hdf5\n",
            "Epoch 75/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0134 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00075: saving model to /media/sysadmin/stock/weights_unet/13_unet-0075.hdf5\n",
            "Epoch 76/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00076: saving model to /media/sysadmin/stock/weights_unet/13_unet-0076.hdf5\n",
            "Epoch 77/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0123 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00077: saving model to /media/sysadmin/stock/weights_unet/13_unet-0077.hdf5\n",
            "Epoch 78/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00078: saving model to /media/sysadmin/stock/weights_unet/13_unet-0078.hdf5\n",
            "Epoch 79/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0119 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00079: saving model to /media/sysadmin/stock/weights_unet/13_unet-0079.hdf5\n",
            "Epoch 80/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0140 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00080: saving model to /media/sysadmin/stock/weights_unet/13_unet-0080.hdf5\n",
            "Epoch 81/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0100 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00081: saving model to /media/sysadmin/stock/weights_unet/13_unet-0081.hdf5\n",
            "Epoch 82/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0112 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00082: saving model to /media/sysadmin/stock/weights_unet/13_unet-0082.hdf5\n",
            "Epoch 83/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0114 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00083: saving model to /media/sysadmin/stock/weights_unet/13_unet-0083.hdf5\n",
            "Epoch 84/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0618 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00084: saving model to /media/sysadmin/stock/weights_unet/13_unet-0084.hdf5\n",
            "Epoch 85/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0228 - val_accuracy: 0.9966\n",
            "\n",
            "Epoch 00085: saving model to /media/sysadmin/stock/weights_unet/13_unet-0085.hdf5\n",
            "Epoch 86/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 2.6801 - val_accuracy: 0.9132\n",
            "\n",
            "Epoch 00086: saving model to /media/sysadmin/stock/weights_unet/13_unet-0086.hdf5\n",
            "Epoch 87/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0096 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00087: saving model to /media/sysadmin/stock/weights_unet/13_unet-0087.hdf5\n",
            "Epoch 88/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0079 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00088: saving model to /media/sysadmin/stock/weights_unet/13_unet-0088.hdf5\n",
            "Epoch 89/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0076 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00089: saving model to /media/sysadmin/stock/weights_unet/13_unet-0089.hdf5\n",
            "Epoch 90/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0229 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00090: saving model to /media/sysadmin/stock/weights_unet/13_unet-0090.hdf5\n",
            "Epoch 91/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00091: saving model to /media/sysadmin/stock/weights_unet/13_unet-0091.hdf5\n",
            "Epoch 92/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00092: saving model to /media/sysadmin/stock/weights_unet/13_unet-0092.hdf5\n",
            "Epoch 93/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00093: saving model to /media/sysadmin/stock/weights_unet/13_unet-0093.hdf5\n",
            "Epoch 94/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0068 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00094: saving model to /media/sysadmin/stock/weights_unet/13_unet-0094.hdf5\n",
            "Epoch 95/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00095: saving model to /media/sysadmin/stock/weights_unet/13_unet-0095.hdf5\n",
            "Epoch 96/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.0072 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00096: saving model to /media/sysadmin/stock/weights_unet/13_unet-0096.hdf5\n",
            "Epoch 97/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00097: saving model to /media/sysadmin/stock/weights_unet/13_unet-0097.hdf5\n",
            "Epoch 98/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0062 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00098: saving model to /media/sysadmin/stock/weights_unet/13_unet-0098.hdf5\n",
            "Epoch 99/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0067 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00099: saving model to /media/sysadmin/stock/weights_unet/13_unet-0099.hdf5\n",
            "Epoch 100/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00100: saving model to /media/sysadmin/stock/weights_unet/13_unet-0100.hdf5\n",
            "Epoch 101/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00101: saving model to /media/sysadmin/stock/weights_unet/13_unet-0101.hdf5\n",
            "Epoch 102/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00102: saving model to /media/sysadmin/stock/weights_unet/13_unet-0102.hdf5\n",
            "Epoch 103/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00103: saving model to /media/sysadmin/stock/weights_unet/13_unet-0103.hdf5\n",
            "Epoch 104/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 0.0057 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00104: saving model to /media/sysadmin/stock/weights_unet/13_unet-0104.hdf5\n",
            "Epoch 105/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00105: saving model to /media/sysadmin/stock/weights_unet/13_unet-0105.hdf5\n",
            "Epoch 106/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00106: saving model to /media/sysadmin/stock/weights_unet/13_unet-0106.hdf5\n",
            "Epoch 107/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00107: saving model to /media/sysadmin/stock/weights_unet/13_unet-0107.hdf5\n",
            "Epoch 108/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00108: saving model to /media/sysadmin/stock/weights_unet/13_unet-0108.hdf5\n",
            "Epoch 109/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00109: saving model to /media/sysadmin/stock/weights_unet/13_unet-0109.hdf5\n",
            "Epoch 110/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00110: saving model to /media/sysadmin/stock/weights_unet/13_unet-0110.hdf5\n",
            "Epoch 111/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.0062 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00111: saving model to /media/sysadmin/stock/weights_unet/13_unet-0111.hdf5\n",
            "Epoch 112/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00112: saving model to /media/sysadmin/stock/weights_unet/13_unet-0112.hdf5\n",
            "Epoch 113/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00113: saving model to /media/sysadmin/stock/weights_unet/13_unet-0113.hdf5\n",
            "Epoch 114/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00114: saving model to /media/sysadmin/stock/weights_unet/13_unet-0114.hdf5\n",
            "Epoch 115/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00115: saving model to /media/sysadmin/stock/weights_unet/13_unet-0115.hdf5\n",
            "Epoch 116/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0027 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00116: saving model to /media/sysadmin/stock/weights_unet/13_unet-0116.hdf5\n",
            "Epoch 117/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00117: saving model to /media/sysadmin/stock/weights_unet/13_unet-0117.hdf5\n",
            "Epoch 118/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.0057 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00118: saving model to /media/sysadmin/stock/weights_unet/13_unet-0118.hdf5\n",
            "Epoch 119/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0025 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00119: saving model to /media/sysadmin/stock/weights_unet/13_unet-0119.hdf5\n",
            "Epoch 120/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 0.0055 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00120: saving model to /media/sysadmin/stock/weights_unet/13_unet-0120.hdf5\n",
            "Epoch 121/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00121: saving model to /media/sysadmin/stock/weights_unet/13_unet-0121.hdf5\n",
            "Epoch 122/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0024 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00122: saving model to /media/sysadmin/stock/weights_unet/13_unet-0122.hdf5\n",
            "Epoch 123/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00123: saving model to /media/sysadmin/stock/weights_unet/13_unet-0123.hdf5\n",
            "Epoch 124/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00124: saving model to /media/sysadmin/stock/weights_unet/13_unet-0124.hdf5\n",
            "Epoch 125/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00125: saving model to /media/sysadmin/stock/weights_unet/13_unet-0125.hdf5\n",
            "Epoch 126/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.0054 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00126: saving model to /media/sysadmin/stock/weights_unet/13_unet-0126.hdf5\n",
            "Epoch 127/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 0.0075 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00127: saving model to /media/sysadmin/stock/weights_unet/13_unet-0127.hdf5\n",
            "Epoch 128/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00128: saving model to /media/sysadmin/stock/weights_unet/13_unet-0128.hdf5\n",
            "Epoch 129/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00129: saving model to /media/sysadmin/stock/weights_unet/13_unet-0129.hdf5\n",
            "Epoch 130/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0021 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00130: saving model to /media/sysadmin/stock/weights_unet/13_unet-0130.hdf5\n",
            "Epoch 131/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0020 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00131: saving model to /media/sysadmin/stock/weights_unet/13_unet-0131.hdf5\n",
            "Epoch 132/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0020 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00132: saving model to /media/sysadmin/stock/weights_unet/13_unet-0132.hdf5\n",
            "Epoch 133/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0019 - accuracy: 0.9982 - val_loss: 0.0051 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00133: saving model to /media/sysadmin/stock/weights_unet/13_unet-0133.hdf5\n",
            "Epoch 134/200\n",
            "108/108 [==============================] - 9s 83ms/step - loss: 0.0019 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00134: saving model to /media/sysadmin/stock/weights_unet/13_unet-0134.hdf5\n",
            "Epoch 135/200\n",
            "108/108 [==============================] - 8s 79ms/step - loss: 0.0019 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00135: saving model to /media/sysadmin/stock/weights_unet/13_unet-0135.hdf5\n",
            "Epoch 136/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0019 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00136: saving model to /media/sysadmin/stock/weights_unet/13_unet-0136.hdf5\n",
            "Epoch 137/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0018 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00137: saving model to /media/sysadmin/stock/weights_unet/13_unet-0137.hdf5\n",
            "Epoch 138/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0018 - accuracy: 0.9982 - val_loss: 0.0052 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00138: saving model to /media/sysadmin/stock/weights_unet/13_unet-0138.hdf5\n",
            "Epoch 139/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0018 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00139: saving model to /media/sysadmin/stock/weights_unet/13_unet-0139.hdf5\n",
            "Epoch 140/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0018 - accuracy: 0.9982 - val_loss: 0.0052 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00140: saving model to /media/sysadmin/stock/weights_unet/13_unet-0140.hdf5\n",
            "Epoch 141/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00141: saving model to /media/sysadmin/stock/weights_unet/13_unet-0141.hdf5\n",
            "Epoch 142/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0045 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00142: saving model to /media/sysadmin/stock/weights_unet/13_unet-0142.hdf5\n",
            "Epoch 143/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0060 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00143: saving model to /media/sysadmin/stock/weights_unet/13_unet-0143.hdf5\n",
            "Epoch 144/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00144: saving model to /media/sysadmin/stock/weights_unet/13_unet-0144.hdf5\n",
            "Epoch 145/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00145: saving model to /media/sysadmin/stock/weights_unet/13_unet-0145.hdf5\n",
            "Epoch 146/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00146: saving model to /media/sysadmin/stock/weights_unet/13_unet-0146.hdf5\n",
            "Epoch 147/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00147: saving model to /media/sysadmin/stock/weights_unet/13_unet-0147.hdf5\n",
            "Epoch 148/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00148: saving model to /media/sysadmin/stock/weights_unet/13_unet-0148.hdf5\n",
            "Epoch 149/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00149: saving model to /media/sysadmin/stock/weights_unet/13_unet-0149.hdf5\n",
            "Epoch 150/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00150: saving model to /media/sysadmin/stock/weights_unet/13_unet-0150.hdf5\n",
            "Epoch 151/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00151: saving model to /media/sysadmin/stock/weights_unet/13_unet-0151.hdf5\n",
            "Epoch 152/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 0.0043 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00152: saving model to /media/sysadmin/stock/weights_unet/13_unet-0152.hdf5\n",
            "Epoch 153/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 0.0045 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00153: saving model to /media/sysadmin/stock/weights_unet/13_unet-0153.hdf5\n",
            "Epoch 154/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00154: saving model to /media/sysadmin/stock/weights_unet/13_unet-0154.hdf5\n",
            "Epoch 155/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00155: saving model to /media/sysadmin/stock/weights_unet/13_unet-0155.hdf5\n",
            "Epoch 156/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00156: saving model to /media/sysadmin/stock/weights_unet/13_unet-0156.hdf5\n",
            "Epoch 157/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00157: saving model to /media/sysadmin/stock/weights_unet/13_unet-0157.hdf5\n",
            "Epoch 158/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00158: saving model to /media/sysadmin/stock/weights_unet/13_unet-0158.hdf5\n",
            "Epoch 159/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00159: saving model to /media/sysadmin/stock/weights_unet/13_unet-0159.hdf5\n",
            "Epoch 160/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00160: saving model to /media/sysadmin/stock/weights_unet/13_unet-0160.hdf5\n",
            "Epoch 161/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00161: saving model to /media/sysadmin/stock/weights_unet/13_unet-0161.hdf5\n",
            "Epoch 162/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0040 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00162: saving model to /media/sysadmin/stock/weights_unet/13_unet-0162.hdf5\n",
            "Epoch 163/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00163: saving model to /media/sysadmin/stock/weights_unet/13_unet-0163.hdf5\n",
            "Epoch 164/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0040 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00164: saving model to /media/sysadmin/stock/weights_unet/13_unet-0164.hdf5\n",
            "Epoch 165/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0043 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00165: saving model to /media/sysadmin/stock/weights_unet/13_unet-0165.hdf5\n",
            "Epoch 166/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00166: saving model to /media/sysadmin/stock/weights_unet/13_unet-0166.hdf5\n",
            "Epoch 167/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00167: saving model to /media/sysadmin/stock/weights_unet/13_unet-0167.hdf5\n",
            "Epoch 168/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00168: saving model to /media/sysadmin/stock/weights_unet/13_unet-0168.hdf5\n",
            "Epoch 169/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00169: saving model to /media/sysadmin/stock/weights_unet/13_unet-0169.hdf5\n",
            "Epoch 170/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00170: saving model to /media/sysadmin/stock/weights_unet/13_unet-0170.hdf5\n",
            "Epoch 171/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00171: saving model to /media/sysadmin/stock/weights_unet/13_unet-0171.hdf5\n",
            "Epoch 172/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00172: saving model to /media/sysadmin/stock/weights_unet/13_unet-0172.hdf5\n",
            "Epoch 173/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9977\n",
            "\n",
            "Epoch 00173: saving model to /media/sysadmin/stock/weights_unet/13_unet-0173.hdf5\n",
            "Epoch 174/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0035 - accuracy: 0.9978 - val_loss: 8.6613 - val_accuracy: 0.8451\n",
            "\n",
            "Epoch 00174: saving model to /media/sysadmin/stock/weights_unet/13_unet-0174.hdf5\n",
            "Epoch 175/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0028 - accuracy: 0.9978 - val_loss: 0.0070 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00175: saving model to /media/sysadmin/stock/weights_unet/13_unet-0175.hdf5\n",
            "Epoch 176/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0029 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00176: saving model to /media/sysadmin/stock/weights_unet/13_unet-0176.hdf5\n",
            "Epoch 177/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0029 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00177: saving model to /media/sysadmin/stock/weights_unet/13_unet-0177.hdf5\n",
            "Epoch 178/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0015 - accuracy: 0.9982 - val_loss: 0.0031 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00178: saving model to /media/sysadmin/stock/weights_unet/13_unet-0178.hdf5\n",
            "Epoch 179/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0034 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00179: saving model to /media/sysadmin/stock/weights_unet/13_unet-0179.hdf5\n",
            "Epoch 180/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0037 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00180: saving model to /media/sysadmin/stock/weights_unet/13_unet-0180.hdf5\n",
            "Epoch 181/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0038 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00181: saving model to /media/sysadmin/stock/weights_unet/13_unet-0181.hdf5\n",
            "Epoch 182/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0040 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00182: saving model to /media/sysadmin/stock/weights_unet/13_unet-0182.hdf5\n",
            "Epoch 183/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00183: saving model to /media/sysadmin/stock/weights_unet/13_unet-0183.hdf5\n",
            "Epoch 184/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00184: saving model to /media/sysadmin/stock/weights_unet/13_unet-0184.hdf5\n",
            "Epoch 185/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0043 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00185: saving model to /media/sysadmin/stock/weights_unet/13_unet-0185.hdf5\n",
            "Epoch 186/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00186: saving model to /media/sysadmin/stock/weights_unet/13_unet-0186.hdf5\n",
            "Epoch 187/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0040 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00187: saving model to /media/sysadmin/stock/weights_unet/13_unet-0187.hdf5\n",
            "Epoch 188/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00188: saving model to /media/sysadmin/stock/weights_unet/13_unet-0188.hdf5\n",
            "Epoch 189/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0043 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00189: saving model to /media/sysadmin/stock/weights_unet/13_unet-0189.hdf5\n",
            "Epoch 190/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00190: saving model to /media/sysadmin/stock/weights_unet/13_unet-0190.hdf5\n",
            "Epoch 191/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0035 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00191: saving model to /media/sysadmin/stock/weights_unet/13_unet-0191.hdf5\n",
            "Epoch 192/200\n",
            "108/108 [==============================] - 9s 80ms/step - loss: 0.0014 - accuracy: 0.9982 - val_loss: 0.0037 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00192: saving model to /media/sysadmin/stock/weights_unet/13_unet-0192.hdf5\n",
            "Epoch 193/200\n",
            "108/108 [==============================] - 9s 84ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0039 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00193: saving model to /media/sysadmin/stock/weights_unet/13_unet-0193.hdf5\n",
            "Epoch 194/200\n",
            "108/108 [==============================] - 9s 80ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0038 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00194: saving model to /media/sysadmin/stock/weights_unet/13_unet-0194.hdf5\n",
            "Epoch 195/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00195: saving model to /media/sysadmin/stock/weights_unet/13_unet-0195.hdf5\n",
            "Epoch 196/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00196: saving model to /media/sysadmin/stock/weights_unet/13_unet-0196.hdf5\n",
            "Epoch 197/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00197: saving model to /media/sysadmin/stock/weights_unet/13_unet-0197.hdf5\n",
            "Epoch 198/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00198: saving model to /media/sysadmin/stock/weights_unet/13_unet-0198.hdf5\n",
            "Epoch 199/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00199: saving model to /media/sysadmin/stock/weights_unet/13_unet-0199.hdf5\n",
            "Epoch 200/200\n",
            "108/108 [==============================] - 8s 78ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9978\n",
            "\n",
            "Epoch 00200: saving model to /media/sysadmin/stock/weights_unet/13_unet-0200.hdf5\n",
            "UNet execution time is:  0:29:04.381997\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "'''\n",
        "UNet\n",
        "'''\n",
        "unet_model = UNet(input_shape)\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(unet_model.summary())\n",
        "\n",
        "start1 = datetime.now()\n",
        "\n",
        "#weigth_path=os.getcwd()+\"/weights_unet/unet-{epoch:04d}.hdf5\"\n",
        "weigth_path=\"/media/sysadmin/stock/weights_unet/13_unet-{epoch:04d}.hdf5\"\n",
        "cp_callback=ModelCheckpoint(\n",
        "    weigth_path,verbose=1,save_weights_only=True,\n",
        "    save_freq=\"epoch\"\n",
        ")\n",
        "unet_history = unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=200)\n",
        "\n",
        "stop1 = datetime.now()\n",
        "#Execution time of the model\n",
        "execution_time_Unet = stop1-start1\n",
        "print(\"UNet execution time is: \", execution_time_Unet)\n",
        "\n",
        "unet_model.save('AksiyalSON_MS_SCI_MAKALE_IEEE_son_UNet13.hdf5')\n",
        "\n",
        "\n",
        "Unet_model_history_df = pd.DataFrame(unet_history.history)\n",
        "Unet_model_history_csv_file = 'Unet_AksiyalSON_MS_SCI_MAKALE_IEEE_13.csv'\n",
        "\n",
        "with open('Unet_AksiyalSON_MS_SCI_MAKALE_IEEE_13.csv', mode='w') as f:\n",
        "    Unet_model_history_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e7e050",
      "metadata": {
        "id": "a1e7e050"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "fractal2_UNet\n",
        "'''\n",
        "fractal2_unet_model = fractal2_UNet(input_shape)\n",
        "fractal2_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(fractal2_unet_model .summary())\n",
        "\n",
        "start5 = datetime.now()\n",
        "\n",
        "#weigth_path=os.getcwd()+\"/weights_unet/unet-{epoch:04d}.hdf5\"\n",
        "weigth_path=\"/media/sysadmin/stock/weights_fractal/13_fractalunet-{epoch:04d}.hdf5\"\n",
        "cp_callback=ModelCheckpoint(\n",
        "    weigth_path,verbose=1,save_weights_only=True,\n",
        "    save_freq=\"epoch\"\n",
        ")\n",
        "\n",
        "fractal2_unet_history = fractal2_unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=200)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "stop5 = datetime.now()\n",
        "#Execution time of the model\n",
        "execution_time_fractal2_unet = stop5-start5\n",
        "print(\"fractal2 UNet execution time is: \", execution_time_fractal2_unet)\n",
        "\n",
        "#unet_model.save('mitochondria_UNet_50epochs_B_focal.hdf5')\n",
        "fractal2_unet_model.save('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_fractal2_unet13.hdf5')\n",
        "\n",
        "\n",
        "fractal2_unet_history_df = pd.DataFrame(fractal2_unet_history.history)\n",
        "fractal2_unet_history_csv_file = 'AKSİYALSON_MS_SCI_MAKALE_IEEE_1_fractal2_unet13.csv'\n",
        "\n",
        "with open('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_fractal2_unet13.csv', mode='w') as f:\n",
        "    fractal2_unet_history_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628037b3",
      "metadata": {
        "id": "628037b3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Attention UNet\n",
        "'''\n",
        "karma_att_unet_model = Attention_UNet(input_shape)\n",
        "\n",
        "karma_att_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(karma_att_unet_model.summary())\n",
        "start2 = datetime.now()\n",
        "\n",
        "\n",
        "\n",
        "#weigth_path=os.getcwd()+\"/weights_unet/unet-{epoch:04d}.hdf5\"\n",
        "weigth_path=\"/media/sysadmin/stock/weights_att/13_att_unet-{epoch:04d}.hdf5\"\n",
        "cp_callback=ModelCheckpoint(\n",
        "    weigth_path,verbose=1,save_weights_only=True,\n",
        "    save_freq=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "karma_att_unet_history = karma_att_unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=200)\n",
        "\n",
        "stop2 = datetime.now()\n",
        "#Execution time of the model\n",
        "execution_time_karma_Att_Unet = stop2-start2\n",
        "print(\"karma_Attention UNet execution time is: \", execution_time_karma_Att_Unet)\n",
        "\n",
        "#att_unet_model.save('mitochondria_Attention_UNet_50epochs_B_focal.hdf5')\n",
        "karma_att_unet_model.save('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_att_unet_model-13.hdf5')\n",
        "\n",
        "karma_att_unet_history_df = pd.DataFrame(karma_att_unet_history.history)\n",
        "karma_att_unet_history_csv_file = 'AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_att_unet_model-13.csv'\n",
        "\n",
        "with open('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_att_unet_model-13.csv', mode='w') as f:\n",
        "    karma_att_unet_history_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b330ce",
      "metadata": {
        "id": "e3b330ce"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "res_UNet_UNet\n",
        "'''\n",
        "karma_res_UNet_model = res_UNet(input_shape)\n",
        "karma_res_UNet_model.compile(optimizer=Adam(lr = 1e-2), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(karma_res_UNet_model.summary())\n",
        "\n",
        "start3 = datetime.now()\n",
        "\n",
        "#weigth_path=os.getcwd()+\"/weights_unet/unet-{epoch:04d}.hdf5\"\n",
        "weigth_path=\"/media/sysadmin/stock/weights_res/13-resunet-{epoch:04d}.hdf5\"\n",
        "cp_callback=ModelCheckpoint(\n",
        "    weigth_path,verbose=1,save_weights_only=True,\n",
        "    save_freq=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "karma_res_UNet_history = karma_res_UNet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=200)\n",
        "\n",
        "stop3 = datetime.now()\n",
        "#Execution time of the model\n",
        "execution_time_karma_res_UNet_modelres_UNet = stop3-start3\n",
        "print(\"karma_res_UNet_modelres_UNet execution time is: \", execution_time_karma_res_UNet_modelres_UNet)\n",
        "\n",
        "#unet_model.save('mitochondria_UNet_50epochs_B_focal.hdf5')\n",
        "karma_res_UNet_model.save('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_res_UNet_model-13.hdf5')\n",
        "\n",
        "karma_res_UNet_history_df = pd.DataFrame(karma_res_UNet_history.history)\n",
        "karma_res_UNet_history_csv_file = 'AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_res_UNet_model-13.csv'\n",
        "\n",
        "with open('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_res_UNet_model-13.csv', mode='w') as f:\n",
        "    karma_res_UNet_history_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6074914e",
      "metadata": {
        "id": "6074914e"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Attention Residual Unet\n",
        "'''\n",
        "karma_att_res_unet_model = Attention_ResUNet(input_shape)\n",
        "\n",
        "karma_att_res_unet_model.compile(optimizer=Adam(lr = 1e-2), loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# att_res_unet_model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy',\n",
        "#               metrics=['accuracy', jacard_coef])\n",
        "\n",
        "print(karma_att_res_unet_model.summary())\n",
        "\n",
        "\n",
        "start4 = datetime.now()\n",
        "\n",
        "#weigth_path=os.getcwd()+\"/weights_unet/unet-{epoch:04d}.hdf5\"\n",
        "weigth_path=\"/media/sysadmin/stock/weights_resatt/13_resattunet-{epoch:04d}.hdf5\"\n",
        "cp_callback=ModelCheckpoint(\n",
        "    weigth_path,verbose=1,save_weights_only=True,\n",
        "    save_freq=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "karma_att_res_unet_history = karma_att_res_unet_model.fit(X_train, y_train,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=200)\n",
        "stop4 = datetime.now()\n",
        "\n",
        "#Execution time of the model\n",
        "execution_time_karma_att_res = stop4-start4\n",
        "print(\"karma att res cution time is: \", execution_time_karma_att_res)\n",
        "\n",
        "karma_att_res_unet_model.save('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_att_res_unet_model-13.hdf5')\n",
        "\n",
        "\n",
        "karma_att_res_unet_history_df = pd.DataFrame(karma_att_res_unet_history.history)\n",
        "karma_att_res_unet_history_csv_file = 'AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_att_res_unet_model-13.csv'\n",
        "\n",
        "with open('AKSİYALSON_MS_SCI_MAKALE_IEEE_1_karma_att_res_unet_model-13.csv', mode='w') as f:\n",
        "    karma_att_res_unet_history_df.to_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85366158",
      "metadata": {
        "id": "85366158",
        "outputId": "dd5c1822-eca1-4be0-8764-fd6c1a9ebbbf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'unet_history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3e0691345ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#plot the training and validation accuracy and loss at each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unet_history' is not defined"
          ]
        }
      ],
      "source": [
        "#Evaluate the model\n",
        "\n",
        "history = unet_history\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss for Spinalcord Dataset')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#acc = history.history['acc']\n",
        "acc = history.history['accuracy']\n",
        "#val_acc = history.history['val_acc']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy for Spinalcord Dataset')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model = unet_model\n",
        "\t# evaluate model\n",
        "_, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
        "\n",
        "#IOU\n",
        "model = unet_model\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_thresholded = y_pred > 0.5\n",
        "\n",
        "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
        "union = np.logical_or(y_test, y_pred_thresholded)\n",
        "iou_score = np.sum(intersection) / np.sum(union)\n",
        "print(\"IoU socre is: \", iou_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc28c74b",
      "metadata": {
        "id": "cc28c74b"
      },
      "source": [
        "# model deneme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1f8320",
      "metadata": {
        "id": "6a1f8320",
        "outputId": "58ffaf75-cf84-4c40-e9e0-df47d1c302ba"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'unet_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5ed76b310df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unet_model' is not defined"
          ]
        }
      ],
      "source": [
        "import lesionQcMetrics as QcMetric\n",
        "import Metric_eval as EvMetric\n",
        "\n",
        "\n",
        "model = unet_model\n",
        "y_pred=model.predict(X_test)\n",
        "\n",
        "\n",
        "i=0\n",
        "\n",
        "\n",
        "\n",
        "toplam_sp_dice=0\n",
        "toplam_sp_jaccard=0\n",
        "toplam_sp_ppv=0\n",
        "toplam_sp_precision=0\n",
        "toplam_sp_tpr=0\n",
        "toplam_sp_sensitivity=0\n",
        "toplam_sp_avd=0\n",
        "toplam_sp_ravd =0\n",
        "toplam_sp_assd  =0\n",
        "toplam_sp_volume_correlation=0\n",
        "toplam_sp_lfpr=0\n",
        "toplam_sp_ltpr=0\n",
        "toplam_sp_recall=0\n",
        "toplam_sp_specificity=0\n",
        "toplam_sp_true_negative_rate=0\n",
        "toplam_sp_true_positive_rate=0\n",
        "toplam_sp_positive_predictive_value=0\n",
        "toplam_sp_hd=0\n",
        "toplam_sp_hd95=0\n",
        "toplam_sp_asd=0\n",
        "toplam_sp_volume_change_correlation=0\n",
        "toplam_sp_obj_assd=0\n",
        "toplam_sp_obj_asd=0\n",
        "toplam_sp_obj_tpr=0\n",
        "toplam_sp_obj_fpr=0\n",
        "\n",
        "\n",
        "toplam_MS_dice=0\n",
        "toplam_MS_jaccard=0\n",
        "toplam_MS_ppv=0\n",
        "toplam_MS_precision=0\n",
        "toplam_MS_tpr=0\n",
        "toplam_MS_sensitivity=0\n",
        "toplam_MS_avd=0\n",
        "toplam_MS_ravd =0\n",
        "toplam_MS_assd =0\n",
        "toplam_MS_volume_correlation=0\n",
        "toplam_MS_lfpr=0\n",
        "toplam_MS_ltpr=0\n",
        "toplam_MS_recall=0\n",
        "toplam_MS_specificity=0\n",
        "toplam_MS_true_negative_rate=0\n",
        "toplam_MS_true_positive_rate=0\n",
        "toplam_MS_positive_predictive_value=0\n",
        "toplam_MS_hd=0\n",
        "toplam_MS_hd95=0\n",
        "toplam_MS_asd=0\n",
        "toplam_MS_volume_change_correlation=0\n",
        "toplam_MS_obj_assd=0\n",
        "toplam_MS_obj_asd=0\n",
        "toplam_MS_obj_tpr=0\n",
        "toplam_MS_obj_fpr=0\n",
        "\n",
        "\n",
        "\n",
        "toplam_all_dice=0\n",
        "toplam_all_jaccard=0\n",
        "toplam_all_ppv=0\n",
        "toplam_all_precision=0\n",
        "toplam_all_tpr=0\n",
        "toplam_all_sensitivity=0\n",
        "toplam_all_avd=0\n",
        "toplam_all_ravd =0\n",
        "toplam_all_assd =0\n",
        "toplam_all_volume_correlation=0\n",
        "toplam_all_lfpr=0\n",
        "toplam_all_ltpr=0\n",
        "toplam_all_recall=0\n",
        "toplam_all_specificity=0\n",
        "toplam_all_true_negative_rate=0\n",
        "toplam_all_true_positive_rate=0\n",
        "toplam_all_positive_predictive_value=0\n",
        "toplam_all_hd=0\n",
        "toplam_all_hd95=0\n",
        "toplam_all_asd=0\n",
        "toplam_all_volume_change_correlation=0\n",
        "toplam_all_obj_assd=0\n",
        "toplam_all_obj_asd=0\n",
        "toplam_all_obj_tpr=0\n",
        "toplam_all_obj_fpr=0\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "#     image_number = random.randint(0, (len(X_test)-1))\n",
        "    #image_number=0\n",
        "    image_number=i\n",
        "\n",
        "    y_testR=img_as_ubyte(y_test[image_number])\n",
        "\n",
        "    y_predR=img_as_ubyte(y_pred[image_number])\n",
        "    #print(y_predR)\n",
        "    predB=takeSame(y_predR,85,170,128)\n",
        "    testB=takeSame(y_testR,85,170,128)\n",
        "    predC=takeSame(y_predR,170,255,255)\n",
        "    testC=takeSame(y_testR,170,255,255)\n",
        "    predD=takeSame(y_predR,85,255,255) # tüm segmentasyon tek sınıf\n",
        "    testD=takeSame(y_testR,85,255,255) # tüm segmentasyon tek sınıf\n",
        "\n",
        "    \"\"\" MS  all metrics \"\"\"\n",
        "\n",
        "    MS_dice=EvMetric.dc(predB,testB)\n",
        "    MS_jaccard=EvMetric.jc(predB,testB)\n",
        "    MS_precision=EvMetric.precision(predB,testB)\n",
        "    MS_recall=EvMetric.recall(predB,testB)\n",
        "    MS_ppv=EvMetric.positive_predictive_value(predB,testB)\n",
        "    MS_sensitivity=EvMetric.sensitivity(predB,testB)\n",
        "    MS_specificity=EvMetric.specificity(predB,testB)\n",
        "    MS_true_negative_rate=EvMetric.true_negative_rate(predB,testB)\n",
        "    MS_true_positive_rate=EvMetric.true_positive_rate(predB,testB)\n",
        "    MS_positive_predictive_value=EvMetric.positive_predictive_value(predB,testB)\n",
        "    MS_hd=EvMetric.hd(predB,testB)\n",
        "    MS_hd95=EvMetric.hd95(predB,testB)\n",
        "    MS_assd=EvMetric.assd(predB,testB)\n",
        "    MS_asd=EvMetric.asd(predB,testB)\n",
        "    MS_ravd=EvMetric.ravd(predB,testB)\n",
        "    MS_volume_correlation=EvMetric.volume_correlation(predB,testB)\n",
        "    MS_volume_change_correlation=EvMetric.volume_change_correlation(predB,testB)\n",
        "    MS_obj_assd=EvMetric.obj_assd(predB,testB)\n",
        "    MS_obj_asd=EvMetric.obj_asd(predB,testB)\n",
        "    MS_obj_fpr=EvMetric.obj_fpr(predB,testB)\n",
        "    MS_obj_tpr=EvMetric.obj_tpr(predB,testB)\n",
        "\n",
        "\n",
        "    \"\"\" spinal without ms metrics \"\"\"\n",
        "\n",
        "\n",
        "    sp_dice=EvMetric.dc(predC,testC)\n",
        "    sp_jaccard=EvMetric.jc(predC,testC)\n",
        "    sp_precision=EvMetric.precision(predC,testC)\n",
        "    sp_recall=EvMetric.recall(predC,testC)\n",
        "    sp_ppv=EvMetric.positive_predictive_value(predC,testC)\n",
        "    sp_sensitivity=EvMetric.sensitivity(predC,testC)\n",
        "    sp_specificity=EvMetric.specificity(predC,testC)\n",
        "    sp_true_negative_rate=EvMetric.true_negative_rate(predC,testC)\n",
        "    sp_true_positive_rate=EvMetric.true_positive_rate(predC,testC)\n",
        "    sp_positive_predictive_value=EvMetric.positive_predictive_value(predC,testC)\n",
        "    sp_hd=EvMetric.hd(predC,testC)\n",
        "    sp_hd95=EvMetric.hd95(predC,testC)\n",
        "    sp_assd=EvMetric.assd(predC,testC)\n",
        "    sp_asd=EvMetric.asd(predC,testC)\n",
        "    sp_ravd=EvMetric.ravd(predC,testC)\n",
        "    sp_volume_correlation=EvMetric.volume_correlation(predC,testC)\n",
        "    sp_volume_change_correlation=EvMetric.volume_change_correlation(predC,testC)\n",
        "    sp_obj_assd=EvMetric.obj_assd(predC,testC)\n",
        "    sp_obj_asd=EvMetric.obj_asd(predC,testC)\n",
        "    sp_obj_tpr=EvMetric.obj_tpr(predC,testC)\n",
        "    sp_obj_fpr=EvMetric.obj_fpr(predC,testC)\n",
        "\n",
        "    \"\"\" ALL spinal all metrics \"\"\"\n",
        "\n",
        "    all_dice=EvMetric.dc(predD,testD)\n",
        "    all_jaccard=EvMetric.jc(predD,testD)\n",
        "    all_precision=EvMetric.precision(predD,testD)\n",
        "    all_recall=EvMetric.recall(predD,testD)\n",
        "    all_ppv=EvMetric.positive_predictive_value(predD,testD)\n",
        "    all_sensitivity=EvMetric.sensitivity(predD,testD)\n",
        "    all_specificity=EvMetric.specificity(predD,testD)\n",
        "    all_true_negative_rate=EvMetric.true_negative_rate(predD,testD)\n",
        "    all_true_positive_rate=EvMetric.true_positive_rate(predD,testD)\n",
        "    all_positive_predictive_value=EvMetric.positive_predictive_value(predD,testD)\n",
        "    all_hd=EvMetric.hd(predD,testD)\n",
        "    all_hd95=EvMetric.hd95(predD,testD)\n",
        "    all_assd=EvMetric.assd(predD,testD)\n",
        "    all_asd=EvMetric.asd(predD,testD)\n",
        "    all_ravd=EvMetric.ravd(predD,testD)\n",
        "    all_volume_correlation=EvMetric.volume_correlation(predD,testD)\n",
        "    all_volume_change_correlation=EvMetric.volume_change_correlation(predD,testD)\n",
        "    all_obj_assd=EvMetric.obj_assd(predD,testD)\n",
        "    all_obj_asd=EvMetric.obj_asd(predD,testD)\n",
        "    all_obj_tpr=EvMetric.obj_tpr(predD,testD)\n",
        "    all_obj_fpr=EvMetric.obj_fpr(predD,testD)\n",
        "\n",
        "    \"toplam spinal hesaplama ve ortalama hespalama \"\n",
        "    toplam_sp_dice=toplam_sp_dice+sp_dice\n",
        "    toplam_sp_jaccard=toplam_sp_jaccard+sp_jaccard\n",
        "    toplam_sp_precision=toplam_sp_precision+sp_precision\n",
        "    toplam_sp_recall=toplam_sp_recall+sp_recall\n",
        "    toplam_sp_ppv=toplam_sp_ppv+sp_ppv\n",
        "    toplam_sp_sensitivity=toplam_sp_sensitivity+sp_sensitivity\n",
        "    toplam_sp_specificity=toplam_sp_specificity+sp_specificity\n",
        "    toplam_sp_true_negative_rate=toplam_sp_true_negative_rate+sp_true_negative_rate\n",
        "    toplam_sp_true_positive_rate=toplam_sp_true_positive_rate+sp_true_positive_rate\n",
        "    toplam_sp_positive_predictive_value=toplam_sp_positive_predictive_value+sp_positive_predictive_value\n",
        "    toplam_sp_hd=toplam_sp_hd+sp_hd\n",
        "    toplam_sp_hd95=toplam_sp_hd95+sp_hd95\n",
        "    toplam_sp_assd=toplam_sp_assd+sp_assd\n",
        "    toplam_sp_asd=toplam_sp_asd+sp_asd\n",
        "    toplam_sp_ravd=toplam_sp_ravd+sp_ravd\n",
        "    toplam_sp_obj_assd=toplam_sp_obj_assd+sp_obj_assd\n",
        "    toplam_sp_obj_asd=toplam_sp_obj_asd+sp_obj_asd\n",
        "    toplam_sp_obj_tpr=toplam_sp_obj_tpr+sp_obj_tpr\n",
        "    toplam_sp_obj_fpr=toplam_sp_obj_fpr+sp_obj_fpr\n",
        "\n",
        "\n",
        "    \"toplam ms hesaplama ve ortalama hespalama \"\n",
        "    toplam_MS_dice=toplam_MS_dice+MS_dice\n",
        "    toplam_MS_jaccard=toplam_MS_jaccard+MS_jaccard\n",
        "    toplam_MS_precision=toplam_MS_precision+MS_precision\n",
        "    toplam_MS_recall=toplam_MS_recall+MS_recall\n",
        "    toplam_MS_ppv=toplam_MS_ppv+MS_ppv\n",
        "    toplam_MS_sensitivity=toplam_MS_sensitivity+MS_sensitivity\n",
        "    toplam_MS_specificity=toplam_MS_specificity+MS_specificity\n",
        "    toplam_MS_true_negative_rate=toplam_MS_true_negative_rate+MS_true_negative_rate\n",
        "    toplam_MS_true_positive_rate=toplam_MS_true_positive_rate+MS_true_positive_rate\n",
        "    toplam_MS_positive_predictive_value=toplam_MS_positive_predictive_value+MS_positive_predictive_value\n",
        "    toplam_MS_hd=toplam_MS_hd+MS_hd\n",
        "    toplam_MS_hd95=toplam_MS_hd95+MS_hd95\n",
        "    toplam_MS_assd=toplam_MS_assd+MS_assd\n",
        "    toplam_MS_asd=toplam_MS_asd+MS_asd\n",
        "    toplam_MS_ravd=toplam_MS_ravd+MS_ravd\n",
        "    toplam_MS_obj_assd=toplam_MS_obj_assd+MS_obj_assd\n",
        "    toplam_MS_obj_asd=toplam_MS_obj_asd+MS_obj_asd\n",
        "    toplam_MS_obj_tpr=toplam_MS_obj_tpr+MS_obj_tpr\n",
        "    toplam_MS_obj_fpr=toplam_MS_obj_fpr+MS_obj_fpr\n",
        "\n",
        "    \"toplam ALL spinal hesaplama ve ortalama hespalama \"\n",
        "    #print(\"Dice Coefficient 2 is: \", dice2)\n",
        "    #print(\"Dice Coefficient ort is: \", dice_coefficient_ort2)\n",
        "\n",
        "    toplam_all_dice=toplam_all_dice+all_dice\n",
        "    toplam_all_jaccard=toplam_all_jaccard+all_jaccard\n",
        "    toplam_all_precision=toplam_all_precision+all_precision\n",
        "    toplam_all_recall=toplam_all_recall+all_recall\n",
        "    toplam_all_ppv=toplam_all_ppv+all_ppv\n",
        "    toplam_all_sensitivity=toplam_all_sensitivity+all_sensitivity\n",
        "    toplam_all_specificity=toplam_all_specificity+all_specificity\n",
        "    toplam_all_true_negative_rate=toplam_all_true_negative_rate+all_true_negative_rate\n",
        "    toplam_all_true_positive_rate=toplam_all_true_positive_rate+all_true_positive_rate\n",
        "    toplam_all_positive_predictive_value=toplam_all_positive_predictive_value+all_positive_predictive_value\n",
        "    toplam_all_hd=toplam_all_hd+all_hd\n",
        "    toplam_all_hd95=toplam_all_hd95+all_hd95\n",
        "    toplam_all_assd=toplam_all_assd+all_assd\n",
        "    toplam_all_asd=toplam_all_asd+all_asd\n",
        "    toplam_all_ravd=toplam_all_ravd+all_ravd\n",
        "    toplam_all_obj_assd=toplam_all_obj_assd+all_obj_assd\n",
        "    toplam_all_obj_asd=toplam_all_obj_asd+all_obj_asd\n",
        "    toplam_all_obj_tpr=toplam_all_obj_tpr+all_obj_tpr\n",
        "    toplam_all_obj_fpr=toplam_all_obj_fpr+all_obj_fpr\n",
        "\n",
        "    print(image_number)\n",
        "    #fig.tight_layout(pad=0.2)\n",
        "    plt.figure(figsize=(24,6))\n",
        "    plt.subplot(1,6,1)\n",
        "    plt.title('Image')\n",
        "    plt.imshow(np.reshape(X_test[image_number], (128, 128)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,6,2)\n",
        "    plt.title('Mask')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.reshape(y_test[image_number], (128, 128)), cmap='gray')\n",
        "    plt.subplot(1,6,3)\n",
        "    plt.title('Spinal Predict with Ms')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.reshape(y_predR, (128, 128)), cmap='gray')\n",
        "    plt.subplot(1,6,4)\n",
        "    plt.title('Spinal Predict without Ms')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.reshape(predC, (128, 128)), cmap='gray')\n",
        "    plt.subplot(1,6,5)\n",
        "    plt.title('Only Ms Predict')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.reshape(predB, (128, 128)), cmap='gray')\n",
        "    plt.subplot(1,6,6)\n",
        "    plt.title('ALL Spinal Predict')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.reshape(predD, (128, 128)), cmap='gray')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"spinal Dice,Jaccard, precision,recall,ppv,sensitivity,specificity: \")\n",
        "    print(\"spinal\", sp_dice,sp_jaccard, sp_precision, sp_recall,sp_ppv,sp_sensitivity,sp_specificity)\n",
        "    print()\n",
        "    print(\"spinal true_negative_rate, true_positive_rate,sp_positive_predictive_value: \")\n",
        "    print(\"spinal\",sp_true_negative_rate,sp_true_positive_rate,sp_positive_predictive_value)\n",
        "    print()\n",
        "    print(\"spinal hd,hd95,assd,asd,sp_ravd: \")\n",
        "    print(\"spinal: \",sp_hd,sp_hd95,sp_assd,sp_asd,sp_ravd )\n",
        "    print()\n",
        "    print(\"spinal sp_volume_correlation,sp_volume_change_correlation: \")\n",
        "    print(\"spinal: \",sp_volume_correlation, sp_volume_change_correlation)\n",
        "    print()\n",
        "    print(\"spinal sp_obj_assd,sp_obj_asd,sp_obj_tpr,sp_obj_fpr: \")\n",
        "    print(\"spinal: \",sp_obj_assd,sp_obj_asd,sp_obj_tpr,sp_obj_fpr)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"MS Dice,Jaccard, precision,recall,ppv,sensitivity,specificity: \")\n",
        "    print(\"MS\", MS_dice,MS_jaccard, MS_precision, MS_recall,MS_ppv,MS_sensitivity,MS_specificity)\n",
        "    print()\n",
        "    print(\"MS true_negative_rate, true_positive_rate,positive_predictive_value: \")\n",
        "    print(\"MS\",MS_true_negative_rate,MS_true_positive_rate,MS_positive_predictive_value)\n",
        "    print()\n",
        "    print(\"MS hd,hd95,assd,asd,ravd: \")\n",
        "    print(\"MS: \",MS_hd,MS_hd95,MS_assd,MS_asd,MS_ravd )\n",
        "    print()\n",
        "    print(\"MS MS_volume_correlation,MS_volume_change_correlation: \")\n",
        "    print(\"MS: \",MS_volume_correlation, MS_volume_change_correlation)\n",
        "    print()\n",
        "    print(\"MS obj_assd,obj_asd,obj_tpr,obj_fpr: \")\n",
        "    print(\"MS: \",MS_obj_assd,MS_obj_asd,MS_obj_tpr,MS_obj_fpr)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    print(\"all Dice,Jaccard, precision,recall,ppv,sensitivity,specificity: \")\n",
        "    print(\"all:\", all_dice,all_jaccard, all_precision, all_recall,all_ppv,all_sensitivity,all_specificity)\n",
        "    print()\n",
        "    print(\"all true_negative_rate, true_positive_rate,positive_predictive_value: \")\n",
        "    print(\"all:\",all_true_negative_rate,all_true_positive_rate,all_positive_predictive_value)\n",
        "    print()\n",
        "    print(\"all hd,hd95,assd,asd,ravd: \")\n",
        "    print(\"all: \",all_hd,all_hd95,all_assd,all_asd,all_ravd )\n",
        "    print()\n",
        "    print(\"all MS_volume_correlation,MS_volume_change_correlation: \")\n",
        "    print(\"all: \",all_volume_correlation, all_volume_change_correlation)\n",
        "    print()\n",
        "    print(\"all obj_assd,obj_asd,obj_tpr,obj_fpr: \")\n",
        "    print(\"all: \",all_obj_assd,all_obj_asd,all_obj_tpr,all_obj_fpr)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"ortalama only spinal metrik hesaplama\")\n",
        "print(\"-----------------------------\")\n",
        "print()\n",
        "print(\"spinal Dice,Jaccard, precision,recall,ppv,sensitivity,specificity: \")\n",
        "print(\"spinal\", toplam_sp_dice/len(X_test),toplam_sp_jaccard/len(X_test), toplam_sp_precision/len(X_test), toplam_sp_recall/len(X_test),toplam_sp_ppv/len(X_test),toplam_sp_sensitivity/len(X_test),toplam_sp_specificity/len(X_test))\n",
        "print()\n",
        "print(\"spinal true_negative_rate, true_positive_rate,sp_positive_predictive_value: \")\n",
        "print(\"spinal\",toplam_sp_true_negative_rate/len(X_test),toplam_sp_true_positive_rate/len(X_test),toplam_sp_positive_predictive_value/len(X_test))\n",
        "print()\n",
        "print(\"spinal hd,hd95,assd,asd,sp_ravd: \")\n",
        "print(\"spinal: \",toplam_sp_hd/len(X_test),toplam_sp_hd95/len(X_test),toplam_sp_assd/len(X_test),toplam_sp_asd/len(X_test),toplam_sp_ravd/len(X_test) )\n",
        "print()\n",
        "print(\"spinal sp_volume_correlation,sp_volume_change_correlation: \")\n",
        "print(\"spinal: \",toplam_sp_volume_correlation/len(X_test), toplam_sp_volume_change_correlation/len(X_test))\n",
        "print()\n",
        "print(\"spinal sp_obj_assd,sp_obj_asd,sp_obj_tpr,sp_obj_fpr: \")\n",
        "print(\"spinal: \",toplam_sp_obj_assd/len(X_test),toplam_sp_obj_asd/len(X_test),toplam_sp_obj_tpr/len(X_test),toplam_sp_obj_fpr/len(X_test))\n",
        "print()\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"ortalama ms  metrik hesaplama\")\n",
        "print(\"-----------------------------\")\n",
        "print(\"MS Dice,Jaccard, precision,recall,ppv,sensitivity,specificity: \")\n",
        "print(\"MS\" ,toplam_MS_dice/len(X_test),toplam_MS_jaccard/len(X_test), toplam_MS_precision/len(X_test), toplam_MS_recall/len(X_test),toplam_MS_ppv/len(X_test),toplam_MS_sensitivity/len(X_test),toplam_MS_specificity/len(X_test))\n",
        "print()\n",
        "print(\"MS true_negative_rate, true_positive_rate,positive_predictive_value: \")\n",
        "print(\"MS\",toplam_MS_true_negative_rate/len(X_test),toplam_MS_true_positive_rate/len(X_test),toplam_MS_positive_predictive_value/len(X_test))\n",
        "print()\n",
        "print(\"MS hd,hd95,assd,asd,ravd: \")\n",
        "print(\"MS: \",toplam_MS_hd/len(X_test),toplam_MS_hd95/len(X_test),toplam_MS_assd/len(X_test),toplam_MS_asd/len(X_test),toplam_MS_ravd/len(X_test))\n",
        "print()\n",
        "print(\"MS MS_volume_correlation,MS_volume_change_correlation: \")\n",
        "print(\"MS: \",toplam_MS_volume_correlation/len(X_test), toplam_MS_volume_change_correlation/len(X_test))\n",
        "print()\n",
        "print(\"MS obj_assd,obj_asd,obj_tpr,obj_fpr: \")\n",
        "print(\"MS: \",toplam_MS_obj_assd/len(X_test),toplam_MS_obj_asd/len(X_test),toplam_MS_obj_tpr/len(X_test),toplam_MS_obj_fpr/len(X_test))\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"ortalama all spinal metrik hesaplama\")\n",
        "print(\"-----------------------------\")\n",
        "print(\"all Dice,Jaccard, precision,recall,ppv,sensitivity,specificity: \")\n",
        "print(\"all:\", toplam_all_dice/len(X_test),toplam_all_jaccard/len(X_test), toplam_all_precision/len(X_test), toplam_all_recall/len(X_test),toplam_all_ppv/len(X_test),toplam_all_sensitivity/len(X_test),toplam_all_specificity/len(X_test))\n",
        "print()\n",
        "print(\"all true_negative_rate, true_positive_rate,positive_predictive_value: \")\n",
        "print(\"all:\",toplam_all_true_negative_rate/len(X_test),toplam_all_true_positive_rate/len(X_test),toplam_all_positive_predictive_value/len(X_test))\n",
        "print()\n",
        "print(\"all hd,hd95,assd,asd,ravd: \")\n",
        "print(\"all: \",toplam_all_hd/len(X_test),toplam_all_hd95/len(X_test),toplam_all_assd/len(X_test),toplam_all_asd/len(X_test),toplam_all_ravd/len(X_test))\n",
        "print()\n",
        "print(\"all MS_volume_correlation,MS_volume_change_correlation: \")\n",
        "print(\"all: \",toplam_all_volume_correlation/len(X_test), toplam_all_volume_change_correlation/len(X_test))\n",
        "print()\n",
        "print(\"all obj_assd,obj_asd,obj_tpr,obj_fpr: \")\n",
        "print(\"all: \",toplam_all_obj_assd/len(X_test),toplam_all_obj_asd/len(X_test),toplam_all_obj_tpr/len(X_test),toplam_all_obj_fpr/len(X_test))\n",
        "print()\n",
        "print()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d1d549a",
      "metadata": {
        "id": "9d1d549a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
